{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNs don't do well on this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os, sys\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from multiprocessing import Pool, Process, Queue\n",
    "\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTS_DIR = '/workspace/persistent-data/earthquake/segments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTS = glob(osp.join(SEGMENTS_DIR, '*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SEGMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SEGMENTS[0], 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_minus</th>\n",
       "      <th>acoustic_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.4681</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.4681</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.4681</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_minus  acoustic_data\n",
       "0  -1.4681            -13\n",
       "1  -1.4681            -15\n",
       "2  -1.4681             -7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PICKLES = '/workspace/persistent-data/earthquake/summaries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {OUT_PICKLES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_summary(segfile):\n",
    "    df = pd.read_pickle(segfile)\n",
    "    feat = 'acoustic_data'\n",
    "    tgt = 't_minus'\n",
    "\n",
    "    f_min = df[feat].min()\n",
    "    f_max = df[feat].max()\n",
    "    f_mean = df[feat].mean()\n",
    "    f_std = df[feat].std()\n",
    "\n",
    "    target = df[tgt].iloc[-1]\n",
    "\n",
    "    out_fn = osp.join(OUT_PICKLES, osp.split(segfile)[1].split('.')[0] + '.pickle')\n",
    "    with open(out_fn, 'wb') as f:\n",
    "        pickle.dump({'f_min': f_min, 'f_max': f_max, \n",
    "                     'f_mean': f_mean, 'f_std': f_std,\n",
    "                     'target': target}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_process(q, processor):\n",
    "    while True:\n",
    "        try:\n",
    "            element = q.get(timeout=0.5)\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        processor(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue(maxsize=len(SEGMENTS))\n",
    "for seg in SEGMENTS:\n",
    "    q.put(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-01-30 05:29:03'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def timestamp():\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-01-30 05:30:17] 153569\n",
      "[2019-01-30 05:30:27] 95626\n",
      "[2019-01-30 05:30:37] 45588\n",
      "[2019-01-30 05:30:47] 0\n"
     ]
    }
   ],
   "source": [
    "procs = [Process(name='process_%d' % i, target=do_process, args=(q, write_summary)) for i in range(24)]\n",
    "for p in procs:\n",
    "    p.start()\n",
    "    \n",
    "while True:\n",
    "    sz = q.qsize()\n",
    "    print('[%s] %d' % (timestamp(), sz))\n",
    "    if sz == 0:\n",
    "        break\n",
    "    time.sleep(10)\n",
    "\n",
    "for p in procs:\n",
    "    p.terminate()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARIES = glob(osp.join(OUT_PICKLES, '*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumdf = pd.DataFrame.from_records([pd.read_pickle(p) for p in SUMMARIES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153600"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sumdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_max</th>\n",
       "      <th>f_mean</th>\n",
       "      <th>f_min</th>\n",
       "      <th>f_std</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.0</td>\n",
       "      <td>5.198730</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>5.836566</td>\n",
       "      <td>-1.468095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>4.991699</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>2.917076</td>\n",
       "      <td>-1.463795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>4.955566</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>5.612995</td>\n",
       "      <td>-1.465895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_max    f_mean  f_min     f_std    target\n",
       "0   43.0  5.198730  -28.0  5.836566 -1.468095\n",
       "1   17.0  4.991699   -6.0  2.917076 -1.463795\n",
       "2   37.0  4.955566  -23.0  5.612995 -1.465895"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumdf.to_pickle(osp.join(OUT_PICKLES, 'all.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumdf = pd.read_pickle(osp.join(OUT_PICKLES, 'all.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumdf = sumdf.iloc[np.random.permutation(len(sumdf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "N_train = int(0.9 * len(sumdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(sumdf.iloc[:N_train].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = scaler.transform(sumdf.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.fit(vals[:N_train,:4], vals[:N_train,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = svr.predict(vals[N_train:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(scaler.inverse_transform(np.hstack((vals[N_train:,:4], np.asarray([preds]).T))),\n",
    "                     columns=sumdf.columns.tolist()[:4] + ['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae=2.7308\n"
     ]
    }
   ],
   "source": [
    "print('mae=%.4f' % mean_absolute_error(sumdf['target'].iloc[N_train:], preds['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NuSVR(C=1.0, cache_size=200, coef0=0.0, degree=3, gamma='auto_deprecated',\n",
       "   kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001,\n",
       "   verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusvr = NuSVR()\n",
    "nusvr.fit(vals[:N_train,:4], vals[:N_train,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nupreds = nusvr.predict(vals[N_train:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nupreds = pd.DataFrame(scaler.inverse_transform(np.hstack((vals[N_train:,:4], np.asarray([nupreds]).T))),\n",
    "                     columns=sumdf.columns.tolist()[:4] + ['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae=2.7471\n"
     ]
    }
   ],
   "source": [
    "print('mae=%.4f' % mean_absolute_error(sumdf['target'].iloc[N_train:], nupreds['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

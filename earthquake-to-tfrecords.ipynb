{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake data to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, Process, Queue\n",
    "import os.path as osp\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTS_DIR = '/workspace/persistent-data/earthquake/segments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_SEGMENTS = 1\n",
    "NORMALIZE = False\n",
    "RANGE = [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = glob.glob(osp.join(SEGMENTS_DIR, '*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp():\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORMALIZE:\n",
    "    # Get range values\n",
    "    range_pickle_filename = osp.join(osp.dirname(SEGMENTS_DIR), 'range.pickle')\n",
    "    ranges = {}\n",
    "    for i, segment in enumerate(segments):\n",
    "        df = pd.read_pickle(segment)\n",
    "        for c in df.columns:\n",
    "            if c not in ranges:\n",
    "                ranges[c] = {}\n",
    "                ranges[c]['min'] = 999999999\n",
    "                ranges[c]['max'] = -999999999\n",
    "            ranges[c]['min'] = min(ranges[c]['min'], df[c].min())\n",
    "            ranges[c]['max'] = max(ranges[c]['max'], df[c].max())\n",
    "        \n",
    "        n = i+1\n",
    "        if n % 10000 == 0:\n",
    "            print('[%s] Examined %d segments' % (timestamp(), n))\n",
    "    with open(range_pickle_filename, 'wb') as f:\n",
    "        pickle.dump(ranges, f)\n",
    "    print('wrote ranges to %s' % range_pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acoustic_data': {'max': 5444, 'min': -5515},\n",
       " 't_minus': {'max': -9.550396316600001e-05, 'min': -16.1074}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(osp.join(osp.dirname(SEGMENTS_DIR), 'range.pickle'), 'rb') as f:\n",
    "    ranges = pickle.load(f)\n",
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = np.random.permutation(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = int(len(segments) * 0.85)\n",
    "trainsegs = segments[:N_TRAIN]\n",
    "testsegs = segments[N_TRAIN:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfrecord_defs(segfiles, name):\n",
    "    return [{'%s-%d' % (name, i): segfiles[i]} for i in range(len(segfiles))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130560, 23040)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainsegs), len(testsegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parts = get_tfrecord_defs(trainsegs, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parts = get_tfrecord_defs(testsegs, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130560, 23040)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_parts), len(test_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test-0': '/workspace/persistent-data/earthquake/segments/54036.pickle'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test-23039': '/workspace/persistent-data/earthquake/segments/111027.pickle'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parts[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to `TFRecords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "# The following functions come from the TFRecords example [https://www.tensorflow.org/tutorials/load_data/tf-records]\n",
    "# and a Float64 hack from https://github.com/tensorflow/tensorflow/issues/12876\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _float64_feature(value):\n",
    "    \"\"\"Returns a bytes_list of encoded float64\"\"\"\n",
    "    value = [str(x).encode() for x in value]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(acoustic_data, tminus):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "    # data type.\n",
    "    \n",
    "    feature = {\n",
    "        'acousticdata': _int64_feature(acoustic_data),\n",
    "        'tminus': _float64_feature(tminus)\n",
    "    }\n",
    "    \n",
    "    # Create a Features message using tf.train.Example.\n",
    "    \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_df(df):\n",
    "    df['acoustic_data'] = df['acoustic_data'].astype(np.int16)\n",
    "    df['t_minus'] = df['t_minus'].astype(np.float64)\n",
    "    example = serialize_example(df['acoustic_data'].values, df['t_minus'].values)\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.log(-pd.read_pickle(segments[0])['t_minus'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /workspace/persistent-data/earthquake/tfrecords2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALES = ['1e0', '1e1', '1e2', '1e3', '1e4', '1e-9', '1e-8', '1e-7',\n",
    "           '1e-6', '1e-5', '1e-4', '1e-3', '1e-2', '1e-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in SCALES:\n",
    "    CMD='mkdir -p /workspace/persistent-data/earthquake/tfrecords2/train/%s' % i\n",
    "    !{CMD}\n",
    "    \n",
    "    CMD='mkdir -p /workspace/persistent-data/earthquake/tfrecords2/test/%s' % i\n",
    "    !{CMD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_segment_package(q):\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            elem = q.get()\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        tfrecords_dir = osp.join(osp.dirname(SEGMENTS_DIR), 'tfrecords2')\n",
    "        name = list(elem.keys())[0]\n",
    "        segfile = elem[name]\n",
    "        df = pd.read_pickle(segfile)\n",
    "        last_label_scale = int(np.log(-df['t_minus'].min()))\n",
    "        last_label_scale_str = SCALES[last_label_scale]\n",
    "        traintest, segnum = name.split('-')\n",
    "        filename = traintest + '-' + segnum\n",
    "        tfrecords_location = osp.join(tfrecords_dir, traintest, last_label_scale_str, filename + '.tfrecords')\n",
    "\n",
    "        with tf.python_io.TFRecordWriter(tfrecords_location) as writer:\n",
    "            writer.write(serialize_df(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROCESSES = 28\n",
    "q = Queue(maxsize=len(segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_parts:\n",
    "    q.put(i)\n",
    "for i in test_parts:\n",
    "    q.put(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = [Process(name='serializer-%d' % num,\n",
    "                     target=serialize_segment_package,\n",
    "                     args=(q,)) for num in range(NUM_PROCESSES)]\n",
    "\n",
    "for p in processes:\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-01-21 06:18:41] Queue size=152445\n",
      "[2019-01-21 06:19:01] Queue size=126829\n",
      "[2019-01-21 06:19:21] Queue size=100843\n",
      "[2019-01-21 06:19:42] Queue size=74929\n",
      "[2019-01-21 06:20:02] Queue size=48885\n",
      "[2019-01-21 06:20:22] Queue size=22709\n",
      "[2019-01-21 06:20:42] Queue size=0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    sz = q.qsize()\n",
    "    print('[%s] Queue size=%d' % (timestamp(), sz))\n",
    "    if sz == 0:\n",
    "        break\n",
    "    time.sleep(20)\n",
    "for p in processes:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-1\ttrain=2967  \ttest=528\n",
      "1e-2\ttrain=1096  \ttest=192\n",
      "1e-3\ttrain=392  \ttest=80\n",
      "1e-4\ttrain=145  \ttest=31\n",
      "1e-5\ttrain=53  \ttest=11\n",
      "1e-6\ttrain=18  \ttest=4\n",
      "1e-7\ttrain=9  \ttest=1\n",
      "1e-8\ttrain=2  \ttest=0\n",
      "1e-9\ttrain=1  \ttest=1\n",
      "1e0\ttrain=29086  \ttest=5086\n",
      "1e1\ttrain=55648  \ttest=9889\n",
      "1e2\ttrain=41143  \ttest=7217\n",
      "1e3\ttrain=0  \ttest=0\n",
      "1e4\ttrain=0  \ttest=0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "trainlens = {}\n",
    "testlens = {}\n",
    "for i in SCALES:\n",
    "    traindir='/workspace/persistent-data/earthquake/tfrecords2/train/%s' % i\n",
    "    testdir='/workspace/persistent-data/earthquake/tfrecords2/test/%s' % i\n",
    "    trainlen = len(os.listdir(traindir))\n",
    "    testlen = len(os.listdir(testdir))\n",
    "    trainlens[i] = trainlen\n",
    "    testlens[i] = testlen\n",
    "for x in sorted(trainlens.keys()):\n",
    "    print('%s\\ttrain=%d  \\ttest=%d' % (x, trainlens[x], testlens[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.38905609893065"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012340980408667956"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read a few records back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record_iterator = tf.python_io.tf_record_iterator('/workspace/persistent-data/earthquake/tfrecords/train/train-0.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize(serialized_example):\n",
    "    #example = tf.train.Example()\n",
    "    #example.ParseFromString(string_record)\n",
    "    features = {\n",
    "        'acousticdata': tf.FixedLenFeature((4096), tf.int64),\n",
    "        'tminus': tf.FixedLenFeature((4096), tf.string)\n",
    "    }\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features=features\n",
    "    )\n",
    "    \n",
    "    features['tminus'] = tf.strings.to_number(string_tensor=features['tminus'], out_type=tf.float64)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_ds = tf.data.Dataset.from_tensor_slices(glob.glob(r'/workspace/persistent-data/earthquake/tfrecords2/train/1e-2/*.tfrecords'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset(files_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(deserialize, num_parallel_calls=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096    4096\n",
      "dtype: int64\n",
      "-0.082595512439\n",
      "4096    4096\n",
      "dtype: int64\n",
      "-0.060695491095000005\n",
      "4096    4096\n",
      "dtype: int64\n",
      "-0.089995510513\n"
     ]
    }
   ],
   "source": [
    "for f in ds.take(3):\n",
    "    print(pd.Series(f['tminus'].numpy().shape, f['acousticdata'].numpy().shape))\n",
    "    print(pd.Series(f['tminus'].numpy()).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0-rc2'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

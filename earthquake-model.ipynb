{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and run Earthquake Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 27 22:13:42 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import lstm_estimator\n",
    "import earthquake_input_fn\n",
    "import lstm_estimator_4096\n",
    "from importlib import reload\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_tf():\n",
    "    global lstm_estimator\n",
    "    global earthquake_input_fn\n",
    "    global lstm_estimator_4096\n",
    "    for i in range(2):\n",
    "        import lstm_estimator\n",
    "        import earthquake_input_fn\n",
    "        import lstm_estimator_4096\n",
    "        reload(lstm_estimator)\n",
    "        reload(earthquake_input_fn)\n",
    "        reload(lstm_estimator_4096)\n",
    "        del lstm_estimator\n",
    "        del earthquake_input_fn\n",
    "        del lstm_estimator_4096\n",
    "    import lstm_estimator\n",
    "    import earthquake_input_fn\n",
    "    import lstm_estimator_4096\n",
    "reload_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_estimator_from_params(batch_size, timesteps, n_feats, feature_columns,\n",
    "#                                 lstm_cell_size, dense_size, learning_rate, dropout_rate=0.5, lambda_l2_reg=0.0005,\n",
    "#                                 label_input_column=None, model_dir=None, eval_every=600):\n",
    "#    \n",
    "#    params = {\n",
    "#        'batch_size': batch_size,\n",
    "#        'timesteps': timesteps,\n",
    "#        'n_feats': n_feats,\n",
    "#        'feature_columns': feature_columns,\n",
    "#        'lstm_cell_size': lstm_cell_size,\n",
    "#        'dense_size': dense_size,\n",
    "#        'learning_rate': learning_rate,\n",
    "#        'dropout_rate': dropout_rate,\n",
    "#        'lambda_l2_reg': lambda_l2_reg,\n",
    "#        'label_input_column': label_input_column\n",
    "#    }\n",
    "#    if model_dir is None:\n",
    "#        model_dir = '/workspace/persistent-data/models/%s' % (time.strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "#        \n",
    "#    config = tf.estimator.RunConfig(model_dir=model_dir,\n",
    "#                                    log_step_count_steps=int(4096 / timesteps),\n",
    "#                                    save_checkpoints_secs=600)\n",
    "#    \n",
    "#    estim = tf.estimator.Estimator(model_fn=lstm_estimator.lstm_model_fn,\n",
    "#                                   params=params,\n",
    "#                                   model_dir=model_dir,\n",
    "#                                   config=config)\n",
    "#    return estim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator_4096_from_params(batch_size, timesteps, n_feats, feature_columns,\n",
    "                                 lstm_cell_size, dense_size, learning_rate, dropout_rate=0.5, time_pool=8, lambda_l2_reg=0.0005,\n",
    "                                 label_input_column=None, model_dir=None, eval_every=600):\n",
    "    \n",
    "    params = {\n",
    "        'batch_size': batch_size,\n",
    "        'timesteps': timesteps,\n",
    "        'n_feats': n_feats,\n",
    "        'feature_columns': feature_columns,\n",
    "        'lstm_cell_size': lstm_cell_size,\n",
    "        'dense_size': dense_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'lambda_l2_reg': lambda_l2_reg,\n",
    "        'label_input_column': label_input_column,\n",
    "        'time_pool': time_pool\n",
    "    }\n",
    "    if model_dir is None:\n",
    "        model_dir = '/workspace/persistent-data/models/%s' % (time.strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "        \n",
    "    config = tf.estimator.RunConfig(model_dir=model_dir,\n",
    "                                    log_step_count_steps=int(4096 / timesteps) * 20,\n",
    "                                    save_checkpoints_secs=600)\n",
    "    \n",
    "    estim = tf.estimator.Estimator(model_fn=lstm_estimator_4096.lstm_4096_model_fn,\n",
    "                                   params=params,\n",
    "                                   model_dir=model_dir,\n",
    "                                   config=config)\n",
    "    return estim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_and_evaluate_estimator(earthquake_data_dir, scales, eval_every, eval_count, batch_size,\n",
    "#                                 timesteps, n_feats, feature_columns, lstm_cell_size, dense_size, learning_rate,\n",
    "#                                 dropout_rate, lambda_l2_reg, model_dir=None):\n",
    "#    \n",
    "#    estim = create_estimator_from_params(batch_size, timesteps, n_feats, feature_columns=feature_columns,\n",
    "#                                         lstm_cell_size=lstm_cell_size, dense_size=dense_size, learning_rate=learning_rate,\n",
    "#                                         dropout_rate=dropout_rate, lambda_l2_reg=lambda_l2_reg,\n",
    "#                                         label_input_column=None, model_dir=model_dir, eval_every=eval_every)\n",
    "#    \n",
    "#    trainspec = tf.estimator.TrainSpec(input_fn=lambda: earthquake_input_fn.earthquake_input_fn2(earthquake_data_dir,\n",
    "#                                                                             batch_size,\n",
    "#                                                                             timesteps,\n",
    "#                                                                             scales=scales,\n",
    "#                                                                             traintest='train'),\n",
    "#                                       max_steps=1000000)\n",
    "#    \n",
    "#    evalspec = tf.estimator.EvalSpec(input_fn=lambda: earthquake_input_fn.earthquake_input_fn2(earthquake_data_dir,\n",
    "#                                                                           batch_size,\n",
    "#                                                                           timesteps,\n",
    "#                                                                           scales=scales,\n",
    "#                                                                           traintest='test'),\n",
    "#                                     steps=int(eval_count * (4096/timesteps)),\n",
    "#                                     start_delay_secs=1, throttle_secs=eval_every)\n",
    "#    \n",
    "#    return estim, trainspec, evalspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_estimator_4096(earthquake_data_dir, scales, eval_every, eval_count, batch_size,\n",
    "                                      timesteps, n_feats, feature_columns, lstm_cell_size, dense_size, learning_rate,\n",
    "                                      dropout_rate, time_pool, lambda_l2_reg, model_dir=None):\n",
    "    \n",
    "    estim = create_estimator_4096_from_params(batch_size, timesteps, n_feats, feature_columns=feature_columns,\n",
    "                                              lstm_cell_size=lstm_cell_size, dense_size=dense_size, learning_rate=learning_rate,\n",
    "                                              dropout_rate=dropout_rate, time_pool=time_pool, lambda_l2_reg=lambda_l2_reg,\n",
    "                                              label_input_column=None, model_dir=model_dir, eval_every=eval_every)\n",
    "    \n",
    "    trainspec = tf.estimator.TrainSpec(input_fn=lambda: earthquake_input_fn.earthquake_input_fn2(earthquake_data_dir,\n",
    "                                                                             batch_size,\n",
    "                                                                             timesteps,\n",
    "                                                                             scales=scales,\n",
    "                                                                             traintest='train'),\n",
    "                                       max_steps=1000000)\n",
    "    \n",
    "    evalspec = tf.estimator.EvalSpec(input_fn=lambda: earthquake_input_fn.earthquake_input_fn2(earthquake_data_dir,\n",
    "                                                                           batch_size,\n",
    "                                                                           timesteps,\n",
    "                                                                           scales=scales,\n",
    "                                                                           traintest='test'),\n",
    "                                     steps=int(eval_count * (4096/timesteps)),\n",
    "                                     start_delay_secs=1, throttle_secs=eval_every)\n",
    "    \n",
    "    return estim, trainspec, evalspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload_tf()\n",
    "#\n",
    "#EARTHQUAKE_DATA_DIR = '/workspace/persistent-data/earthquake/tfrecords2'\n",
    "#BATCH_SIZE=64\n",
    "#TIMESTEPS=4096\n",
    "#LSTM_CELL_SIZE=[64, 64]\n",
    "#DENSE_SIZE=[64, 64]\n",
    "#LEARNING_RATE=0.005\n",
    "#DROPOUT_RATE=0.5\n",
    "#LAMBDA_L2_REG=0.0005\n",
    "#STEPS_PER_BATCH = int(4096/TIMESTEPS)\n",
    "#EVAL_EVERY_N_SECONDS = 1800\n",
    "#EVAL_NUM_BATCHES = 100\n",
    "#N_FEATS = 1\n",
    "#SCALES = ['1e' + str(i) for i in range(-8,3)]\n",
    "#FEATURE_COLUMNS = [tf.feature_column.numeric_column(key='acousticdata', dtype=tf.int64, shape=(TIMESTEPS,))]\n",
    "#\n",
    "#estim, train_spec, eval_spec = train_and_evaluate_estimator(EARTHQUAKE_DATA_DIR, SCALES, EVAL_EVERY_N_SECONDS,\n",
    "#                                                            EVAL_NUM_BATCHES, BATCH_SIZE, TIMESTEPS, N_FEATS, FEATURE_COLUMNS,\n",
    "#                                                            LSTM_CELL_SIZE, DENSE_SIZE, LEARNING_RATE, DROPOUT_RATE, LAMBDA_L2_REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_is_chief': True, '_device_fn': None, '_global_id_in_cluster': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_secs': 600, '_eval_distribute': None, '_num_ps_replicas': 0, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_experimental_distribute': None, '_master': '', '_tf_random_seed': None, '_task_type': 'worker', '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f54f8bc6358>, '_num_worker_replicas': 1, '_train_distribute': None, '_protocol': None, '_model_dir': '/workspace/persistent-data/models/2019-01-28-01-17-24', '_save_checkpoints_steps': None, '_evaluation_master': '', '_log_step_count_steps': 20, '_service': None}\n"
     ]
    }
   ],
   "source": [
    "reload_tf()\n",
    "\n",
    "EARTHQUAKE_DATA_DIR = '/workspace/persistent-data/earthquake/tfrecords2'\n",
    "BATCH_SIZE=24\n",
    "TIMESTEPS=4096\n",
    "LSTM_CELL_SIZE=[128, 128, 128]\n",
    "DENSE_SIZE=[128, 256, 512]\n",
    "LEARNING_RATE=0.00075\n",
    "DROPOUT_RATE=0.5\n",
    "TIME_POOL=8\n",
    "LAMBDA_L2_REG=0.005\n",
    "STEPS_PER_BATCH = int(4096/TIMESTEPS)\n",
    "EVAL_EVERY_N_SECONDS = 2700\n",
    "EVAL_NUM_BATCHES = 100\n",
    "N_FEATS = 1\n",
    "SCALES = ['1e' + str(i) for i in range(-8,3)]\n",
    "FEATURE_COLUMNS = [tf.feature_column.numeric_column(key='acousticdata', dtype=tf.int64, shape=(TIMESTEPS,))]\n",
    "\n",
    "estim, train_spec, eval_spec = train_and_evaluate_estimator_4096(EARTHQUAKE_DATA_DIR, SCALES, EVAL_EVERY_N_SECONDS,\n",
    "                                                                 EVAL_NUM_BATCHES, BATCH_SIZE, TIMESTEPS, N_FEATS, FEATURE_COLUMNS,\n",
    "                                                                 LSTM_CELL_SIZE, DENSE_SIZE, LEARNING_RATE, DROPOUT_RATE, TIME_POOL, LAMBDA_L2_REG,\n",
    "                                                                 #model_dir='/workspace/persistent-data/models/2019-01-27-22-33-48')\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "FEATURES\n",
      "{'acousticdata': <tf.Tensor 'IteratorGetNext:0' shape=(?, ?) dtype=int64>}\n",
      "--------------------\n",
      "LABELS\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, ?), dtype=float64, device=/device:CPU:0)\n",
      "--------------------\n",
      "MODE\n",
      "train\n",
      "--------------------\n",
      "PARAMS\n",
      "{'timesteps': 4096, 'n_feats': 1, 'dense_size': [128, 256, 512], 'lstm_cell_size': [128, 128, 128], 'batch_size': 24, 'time_pool': 8, 'label_input_column': None, 'dropout_rate': 0.5, 'lambda_l2_reg': 0.005, 'feature_columns': [_NumericColumn(key='acousticdata', shape=(4096,), default_value=None, dtype=tf.int64, normalizer_fn=None)], 'learning_rate': 0.00075}\n",
      "--------------------\n",
      "Tensor(\"input/stack_1:0\", shape=(512, 8, 24, 1), dtype=float32)\n",
      "Tensor(\"input/ArgMax:0\", shape=(512, 24, 1), dtype=int64)\n",
      "Tensor(\"input/GatherNd:0\", shape=(512, 24, 8, 24, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expecting input_shape with 3 dims, got 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-73fa79bddc8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    469\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    609\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1235\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1237\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1238\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/persistent-code/lstm_estimator_4096.py\u001b[0m in \u001b[0;36mlstm_4096_model_fn\u001b[0;34m(features, labels, mode, params)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bi_rnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m           \u001b[0;31m# the user has manually overwritten the build method do we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0;31m# build it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       raise ValueError(\"Expecting input_shape with 3 dims, got %d\" %\n\u001b[0;32m--> 320\u001b[0;31m                        input_shape.ndims)\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m       raise ValueError(\"The last dimension of the inputs to `CudnnRNN` \"\n",
      "\u001b[0;31mValueError\u001b[0m: Expecting input_shape with 3 dims, got 5"
     ]
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(estim, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
